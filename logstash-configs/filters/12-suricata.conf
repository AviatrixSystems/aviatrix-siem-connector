# Suricata IDS/IPS Filter
# Parses Suricata JSON syslog messages from Aviatrix gateways
#
# Behavior controlled by FLATTEN_SURICATA environment variable:
#   FLATTEN_SURICATA=true  → Flattens nested objects for Splunk (recommended)
#   FLATTEN_SURICATA unset → Keeps nested JSON structure for Azure/other outputs
#
# When flattening is enabled:
#   alert.*    → top level (signature, severity, category, etc.)
#   flow.*     → flow_* (pkts_toserver, bytes_toclient, etc.)
#   http.*     → http_* (hostname, url, method, status, user_agent)
#   tls.*      → tls_* (sni, subject, issuer, ja3, fingerprint)
#   dns.*      → dns_* (query, rrname, rrtype, rdata, ttl)
#   smtp.*     → smtp_* (mail_from, rcpt_to, subject)
#   ssh.*      → ssh_client_*, ssh_server_* (software_version, hassh)
#   fileinfo.* → file_* (filename, size, md5, sha256)
#   tcp.*      → tcp_* (state, tcp_flags)
#   metadata.* → meta_* (confidence, signature_severity - arrays take first value)
#
# Always drops high-volume/low-value fields: files, payload, payload_printable, packet

filter {
    if [type] == "syslog" and "suricata[" in [message] {
        grok {
            id => "suricata"
            patterns_dir => ["/usr/share/logstash/patterns"]
            break_on_match => true
            add_tag => ["suricata"]
            tag_on_failure => []
            match => {
                "message" => [
                    # Suricata JSON alert format with syslog priority
                    "<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date} +GW-%{DATA:gw_hostname}-%{IP}%{DATA}suricata\[%{NUMBER}\]: %{GREEDYDATA:suricataData}"
                ]
            }
        }

        # Parse JSON data if it looks like valid JSON (starts with { and contains "event_type")
        if "suricata" in [tags] and [suricataData] =~ /^\{.*"event_type"/ {
            json {
                id => "suricata-data"
                skip_on_invalid_json => true
                source => "suricataData"
                target => "suricataDataJson"
            }
        }

        # Drop non-JSON suricata logs (notices, startup messages)
        if "suricata" in [tags] and !([suricataData] =~ /^\{/) {
            drop {
                id => "suricata-non-json-drop"
            }
        }

        # Drop events that failed JSON parsing
        if "_jsonparsefailure" in [tags] {
            drop {
                id => "suricata-json-failure-drop"
            }
        }

        # Drop Suricata stats events (too verbose, not security relevant)
        if [suricataDataJson][event_type] == "stats" {
            drop {
                id => "suricata-stats-drop"
            }
        }

        # Process Suricata JSON data
        # When FLATTEN_SURICATA=true: Flattens all nested objects for Splunk
        # When FLATTEN_SURICATA!=true: Keeps nested structure for Azure/other outputs
        if "suricata" in [tags] and [suricataDataJson] {
            ruby {
                id => "suricata-process"
                init => '
                    require "json"
                    require "time"

                    def flatten_object(data, obj_name, prefix, skip_keys = [])
                        return {} unless data[obj_name].is_a?(Hash)
                        result = {}
                        data[obj_name].each do |k, v|
                            next if skip_keys.include?(k)
                            if v.is_a?(Hash)
                                v.each do |k2, v2|
                                    next if v2.is_a?(Hash) || v2.is_a?(Array)
                                    result["#{prefix}_#{k}_#{k2}"] = v2
                                end
                            elsif v.is_a?(Array)
                                result["#{prefix}_#{k}"] = v[0] if v[0] && !v[0].is_a?(Hash) && !v[0].is_a?(Array)
                            else
                                result["#{prefix}_#{k}"] = v
                            end
                        end
                        result
                    end
                '
                code => '
                    data = event.get("suricataDataJson")
                    next unless data.is_a?(Hash)

                    # Fields to drop (high-volume/low-value) - applies to all outputs
                    drop_fields = ["files", "payload", "payload_printable", "packet", "tx_guessed", "policy_id"]
                    tls_skip = ["certificate", "chain"]

                    # Calculate unix timestamp from Suricata timestamp
                    unix_time = nil
                    if data["timestamp"]
                        begin
                            unix_time = Time.parse(data["timestamp"]).to_i
                        rescue
                            unix_time = Time.now.to_i
                        end
                    else
                        unix_time = Time.now.to_i
                    end

                    # Check if flattening is enabled (for Splunk)
                    if ENV["FLATTEN_SURICATA"] == "true"
                        flattened = {}

                        # Nested objects to flatten with their prefixes
                        nested_objects = {
                            "flow" => "flow",
                            "http" => "http",
                            "tls" => "tls",
                            "dns" => "dns",
                            "smtp" => "smtp",
                            "ssh" => "ssh",
                            "fileinfo" => "file",
                            "tcp" => "tcp"
                        }

                        # Process each top-level field
                        data.each do |key, value|
                            next if drop_fields.include?(key)

                            if key == "alert" && value.is_a?(Hash)
                                # Flatten alert fields to top level (no prefix)
                                value.each do |alert_key, alert_value|
                                    next if alert_value.is_a?(Hash) || alert_value.is_a?(Array)
                                    flattened[alert_key] = alert_value
                                end
                            elsif key == "metadata" && value.is_a?(Hash)
                                # Handle metadata specially - arrays take first value, skip timestamps
                                value.each do |meta_key, meta_value|
                                    next if ["created_at", "updated_at"].include?(meta_key)
                                    if meta_value.is_a?(Array)
                                        flattened["meta_#{meta_key}"] = meta_value[0] if meta_value[0]
                                    elsif !meta_value.is_a?(Hash)
                                        flattened["meta_#{meta_key}"] = meta_value
                                    end
                                end
                            elsif nested_objects.key?(key)
                                # Flatten known nested objects with appropriate prefix
                                skip_keys = (key == "tls") ? tls_skip : []
                                flattened.merge!(flatten_object(data, key, nested_objects[key], skip_keys))
                            elsif !value.is_a?(Hash) && !value.is_a?(Array)
                                # Keep primitive top-level fields as-is
                                flattened[key] = value
                            end
                        end

                        # Fix http_ prefix duplication (http.http_method → http_method not http_http_method)
                        flattened.keys.select { |k| k.start_with?("http_http_") }.each do |k|
                            new_key = k.sub("http_http_", "http_")
                            flattened[new_key] = flattened.delete(k)
                        end

                        event_data = flattened
                    else
                        # Non-flattened mode: keep nested structure but remove unwanted fields
                        cleaned = data.dup
                        drop_fields.each { |f| cleaned.delete(f) }
                        if cleaned["tls"].is_a?(Hash)
                            tls_skip.each { |f| cleaned["tls"].delete(f) }
                        end
                        event_data = cleaned
                    end

                    # Build complete HEC payload with event as JSON object
                    payload = {
                        "sourcetype" => "aviatrix:ids",
                        "source" => "avx-ids",
                        "host" => event.get("gw_hostname"),
                        "time" => unix_time,
                        "event" => event_data
                    }
                    event.set("[@metadata][suricata_hec_payload]", payload.to_json)
                '
            }
        }
    }
}
