# Aviatrix Log Integration Engine - Assembled Configuration
# Output Type: splunk-hec
# Generated: 2025-12-09 18:40:03 UTC
#
# This file was automatically generated by assemble-config.sh
# Do not edit directly - modify the source modules instead:
#   - logstash-configs/inputs/
#   - logstash-configs/filters/
#   - logstash-configs/outputs/splunk-hec/
#
# To regenerate: ./scripts/assemble-config.sh splunk-hec

# ============================================================================
# INPUT CONFIGURATION
# ============================================================================

# Syslog Input Configuration
# Receives Aviatrix syslog messages on UDP/TCP port 5000

input {
    udp {
        port => 5000
        type => syslog
    }
    tcp {
        port => 5000
        type => syslog
    }
}

# ============================================================================
# FILTER CONFIGURATION
# ============================================================================

# FQDN Firewall Rule Filter
# Parses AviatrixFQDNRule syslog messages

filter {
    if [type] == "syslog" {
        grok {
            id => "fqdn"
            patterns_dir => ["/usr/share/logstash/patterns"]
            add_tag => ["fqdn"]
            break_on_match => true
            match => {
                "message" => [
                    "%{SYSLOG_TIMESTAMP:date}.*AviatrixFQDNRule.*Gateway=%{HOSTNAME:gateway}.*S_IP=%{IP:sip}.*D_IP=%{IP:dip}.*hostname=%{HOSTNAME:hostname}.*state=%{WORD:state}.*drop_reason=%{WORD:drop}.*Rule=%{RULE:rule}.*",
                    "%{SYSLOG_TIMESTAMP:date}.*AviatrixFQDNRule.*Gateway=%{HOSTNAME:gateway}.*S_IP=%{IP:sip}.*D_IP=%{IP:dip}.*hostname=%{HOSTNAME:hostname}.*state=%{WORD:state}.*Rule=%{RULE:rule}.*",
                    "%{SYSLOG_TIMESTAMP:date}.*AviatrixFQDNRule.*Gateway=%{HOSTNAME:gateway}.*S_IP=%{IP:sip}.*D_IP=%{IP:dip}.*hostname=%{HOSTNAME:hostname}.*state=%{WORD:state}.*drop_reason=%{WORD:drop}",
                    "%{SYSLOG_TIMESTAMP:date}.*AviatrixFQDNRule.*Gateway=%{HOSTNAME:gateway}.*S_IP=%{IP:sip}.*D_IP=%{IP:dip}.*hostname=%{HOSTNAME:hostname}.*state=%{WORD:state}.*"
                ]
            }
        }
    }
}

# Controller CMD/API Filter
# Parses AviatrixCMD (V1) and AviatrixAPI (V2.5) syslog messages

# V1 API format (AviatrixCMD)
filter {
    if [type] == "syslog" and !("fqdn" in [tags]) {
        grok {
            id => "cmd-v1"
            patterns_dir => ["/usr/share/logstash/patterns"]
            break_on_match => true
            add_tag => ["cmd", "V1Api"]
            remove_tag => ["_grokparsefailure"]
            match => {
                "message" => [
                    # Format with username at end (reason may be empty)
                    "%{SYSLOG_TIMESTAMP:date}.*Controller-%{IP:controller_ip}.*AviatrixCMD: action=%{WORD:action}, argv=%{DATA:args}, result=%{WORD:result}, reason=%{DATA:reason}, username=%{NOTSPACE:username}",
                    # Format without username (reason may be empty)
                    "%{SYSLOG_TIMESTAMP:date}.*Controller-%{IP:controller_ip}.*AviatrixCMD: action=%{WORD:action}, argv=%{DATA:args}, result=%{WORD:result}, reason=%{DATA:reason}$"
                ]
            }
        }
    }
}

# Set gw_hostname for CMD logs (use controller_ip if available)
filter {
    if "cmd" in [tags] and [controller_ip] {
        mutate {
            id => "cmd-set-hostname"
            add_field => { "gw_hostname" => "Controller-%{controller_ip}" }
        }
    }
}

# Set default value for empty reason field in CMD logs
filter {
    if "cmd" in [tags] and (![reason] or [reason] == "") {
        mutate {
            id => "cmd-default-reason"
            replace => { "reason" => "" }
        }
    }
}

# V2.5 API format (AviatrixAPI)
filter {
    if [type] == "syslog" and !("fqdn" in [tags]) and !("cmd" in [tags]) {
        grok {
            id => "cmd-v2"
            patterns_dir => ["/usr/share/logstash/patterns"]
            break_on_match => true
            add_tag => ["cmd", "V2.5API"]
            remove_tag => ["_grokparsefailure"]
            match => {
                "message" => [
                    "%{SYSLOG_TIMESTAMP:date}.*AviatrixAPI.*url=%{GREEDYDATA:action} user=%{GREEDYDATA:username}? req_data=%{GREEDYDATA:args} resp_status=%{GREEDYDATA:result} resp_data=%{GREEDYDATA:reason}"
                ]
            }
        }
    }
}

# L4 Microsegmentation (eBPF) Filter
# Parses AviatrixGwMicrosegPacket syslog messages
# Supports both legacy 7.x and 8.2+ formats with session fields

filter {
    if [type] == "syslog" and !("fqdn" in [tags] or "cmd" in [tags]) {
        grok {
            id => "microseg"
            patterns_dir => ["/usr/share/logstash/patterns"]
            break_on_match => true
            add_tag => ["microseg", "ebpf"]
            remove_tag => ["_grokparsefailure"]
            match => {
                "message" => [
                    # 8.2+ format: GW-<name>-<ip>-sink with /usr/local/bin/avx-gw-state-sync process and session fields
                    "^<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date} +GW-%{DATA:gw_hostname}-%{IP:gw_ip}%{DATA}AviatrixGwMicrosegPacket: POLICY=%{UUID:uuid} SRC_MAC=%{MAC:src_mac} DST_MAC=%{MAC:dst_mac} IP_SZ=%{NUMBER:ip_size} SRC_IP=%{IP:src_ip} DST_IP=%{IP:dst_ip} PROTO=%{WORD:proto} SRC_PORT=%{NUMBER:src_port} DST_PORT=%{NUMBER:dst_port} DATA=%{NOTSPACE:data_hex} ACT=%{WORD:action} ENFORCED=%{WORD:enforced} SESSION_ID=%{NUMBER:session_id} SESSION_EVENT=%{NUMBER:session_event} SESSION_END_REASON=%{NUMBER:session_end_reason} SESSION_PKT_CNT=%{NUMBER:session_pkt_cnt} SESSION_BYTE_CNT=%{NUMBER:session_byte_cnt} SESSION_DUR=%{NUMBER:session_dur}",

                    # 8.2+ format without session fields (first packet of flow)
                    "^<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date} +GW-%{DATA:gw_hostname}-%{IP:gw_ip}%{DATA}AviatrixGwMicrosegPacket: POLICY=%{UUID:uuid} SRC_MAC=%{MAC:src_mac} DST_MAC=%{MAC:dst_mac} IP_SZ=%{NUMBER:ip_size} SRC_IP=%{IP:src_ip} DST_IP=%{IP:dst_ip} PROTO=%{WORD:proto} SRC_PORT=%{NUMBER:src_port} DST_PORT=%{NUMBER:dst_port} DATA=%{NOTSPACE:data_hex} ACT=%{WORD:action} ENFORCED=%{WORD:enforced}",

                    # Legacy format (SPT/DPT/ACTION)
                    "^<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date} +%{HOSTNAME:gw_hostname} +AviatrixGwMicrosegPacket: SRC_MAC=%{MAC:src_mac} DST_MAC=%{MAC:dst_mac} PROTO=%{WORD:proto} SPT=%{NUMBER:src_port} DPT=%{NUMBER:dst_port} ACTION=%{WORD:action}"
                ]
            }
            remove_field => ["event", "@version", "type", "host"]
        }
    }
}

# Set default values for fields missing in legacy microseg format
filter {
    if "microseg" in [tags] and ![src_ip] {
        mutate {
            id => "microseg-legacy-defaults"
            add_field => {
                "src_ip" => "unknown"
                "dst_ip" => "unknown"
                "uuid" => "legacy-format"
                "enforced" => "unknown"
            }
        }
    }
}

# L7 DCF / MITM (TLS Inspection) Filter
# Parses traffic_server JSON syslog messages and converts to microseg format
# Also creates cloned FQDN events for URL/hostname tracking

filter {
    if [type] == "syslog" and !("fqdn" in [tags] or "cmd" in [tags] or "microseg" in [tags]) {
        grok {
            id => "mitm"
            patterns_dir => ["/usr/share/logstash/patterns"]
            break_on_match => true
            add_tag => ["mitm"]
            remove_tag => ["_grokparsefailure"]
            match => {
                "message" => [
                    # traffic_server JSON format with syslog priority
                    "<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date} +GW-%{DATA:gw_hostname}-%{IP}%{DATA}traffic_server\[%{NUMBER}\]: %{GREEDYDATA:[@metadata][json_payload]}"
                ]
            }
            remove_field => ["event", "@version", "type", "host"]
        }

        # Parse JSON payload
        if "mitm" in [tags] {
            json {
                id => "mitm-json"
                skip_on_invalid_json => true
                source => "[@metadata][json_payload]"
                target => "[@metadata][payload]"
            }
        }

        # Convert MITM to microseg format
        if "mitm" in [tags] and [@metadata][payload] and "_jsonparsefailure" not in [tags] {
            # Use timestamp provided by MITM instead of syslog timestamp
            date {
                id => "mitm-timestamp"
                match => [ "[@metadata][payload][timestamp]", "UNIX" ]
                target => "@timestamp"
                remove_field => "date"
            }

            # Map MITM fields to microseg fields
            mutate {
                id => "mitm-map-to-microseg"
                add_field => {
                    "proto" => "TCP"
                    "action" => "%{[@metadata][payload][action]}"
                    "src_ip" => "%{[@metadata][payload][src]}"
                    "src_port" => "%{[@metadata][payload][src_port]}"
                    "dst_ip" => "%{[@metadata][payload][dest]}"
                    "dst_port" => "%{[@metadata][payload][dest_port]}"
                    "enforced" => "%{[@metadata][payload][enforced]}"
                    "uuid" => "%{[@metadata][payload][decided_by]}"
                    "mitm_sni_hostname" => "%{[@metadata][payload][sni_hostname]}"
                }
            }

            # Normalize DROP action to DENY
            if [@metadata][payload][action] == "DROP" {
                mutate {
                    id => "mitm-map-drop-to-deny"
                    replace => {
                        "[@metadata][payload][action]" => "DENY"
                    }
                }
            }

            # Add URL if present
            if [@metadata][payload][url] {
                mutate {
                    id => "mitm-url-parts"
                    add_field => {
                        "mitm_url_parts" => "%{[@metadata][payload][url]}"
                    }
                }
            }

            # Add decrypted_by if present
            if [@metadata][payload][decrypted_by] {
                mutate {
                    id => "mitm-decrypted-by"
                    add_field => {
                        "mitm_decrypted_by" => "%{[@metadata][payload][decrypted_by]}"
                    }
                }
            }

            # Add the microseg tag for output routing
            mutate {
                id => "mitm-add-microseg-tag"
                add_tag => ["microseg"]
            }

            # Clone event for FQDN tracking
            clone {
                clones => ["fqdn"]
                add_tag => ["fqdn"]
            }
        }
    }
}

# Transform cloned MITM events into FQDN format
filter {
    if "fqdn" in [tags] and "mitm" in [tags] and "microseg" in [tags] {
        if [@metadata][payload][url] {
            mutate {
                id => "fqdn-mitm-add-url"
                add_field => {
                    "url" => "%{[@metadata][payload][url]}"
                }
            }
        }

        # Map MITM microseg fields to FQDN fields
        mutate {
            id => "fqdn-mitm-map-to-fqdn"
            add_field => {
                "sip" => "%{[@metadata][payload][src]}"
                "dip" => "%{[@metadata][payload][dest]}"
                "gateway" => "%{[gw_hostname]}"
                "state" => "MATCHED"
                "hostname" => "%{[@metadata][payload][sni_hostname]}"
                "rule" => "%{[@metadata][payload][sni_hostname]};%{[@metadata][payload][dest_port]}"
            }
            remove_tag => ["microseg", "mitm"]
            remove_field => ["mitm_url_parts", "mitm_decrypted_by", "mitm_sni_hostname", "src_ip", "src_port", "dst_ip", "dst_port", "enforced", "gw_hostname"]
        }
    }
}

# Suricata IDS/IPS Filter
# Parses Suricata JSON syslog messages from Aviatrix gateways
#
# Behavior controlled by FLATTEN_SURICATA environment variable:
#   FLATTEN_SURICATA=true  → Flattens nested objects for Splunk (recommended)
#   FLATTEN_SURICATA unset → Keeps nested JSON structure for Azure/other outputs
#
# When flattening is enabled:
#   alert.*    → top level (signature, severity, category, etc.)
#   flow.*     → flow_* (pkts_toserver, bytes_toclient, etc.)
#   http.*     → http_* (hostname, url, method, status, user_agent)
#   tls.*      → tls_* (sni, subject, issuer, ja3, fingerprint)
#   dns.*      → dns_* (query, rrname, rrtype, rdata, ttl)
#   smtp.*     → smtp_* (mail_from, rcpt_to, subject)
#   ssh.*      → ssh_client_*, ssh_server_* (software_version, hassh)
#   fileinfo.* → file_* (filename, size, md5, sha256)
#   tcp.*      → tcp_* (state, tcp_flags)
#   metadata.* → meta_* (confidence, signature_severity - arrays take first value)
#
# Always drops high-volume/low-value fields: files, payload, payload_printable, packet

filter {
    if [type] == "syslog" and !("fqdn" in [tags] or "cmd" in [tags] or "microseg" in [tags] or "mitm" in [tags]) {
        grok {
            id => "suricata"
            patterns_dir => ["/usr/share/logstash/patterns"]
            break_on_match => true
            add_tag => ["suricata"]
            match => {
                "message" => [
                    # Suricata JSON alert format with syslog priority
                    "<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date} +GW-%{DATA:gw_hostname}-%{IP}%{DATA}suricata\[%{NUMBER}\]: %{GREEDYDATA:suricataData}"
                ]
            }
        }

        # Parse JSON data if it looks like valid JSON (starts with { and contains "event_type")
        if "suricata" in [tags] and [suricataData] =~ /^\{.*"event_type"/ {
            json {
                id => "suricata-data"
                skip_on_invalid_json => true
                source => "suricataData"
                target => "suricataDataJson"
            }
        }

        # Drop non-JSON suricata logs (notices, startup messages)
        if "suricata" in [tags] and !([suricataData] =~ /^\{/) {
            drop {
                id => "suricata-non-json-drop"
            }
        }

        # Drop events that failed JSON parsing
        if "_jsonparsefailure" in [tags] {
            drop {
                id => "suricata-json-failure-drop"
            }
        }

        # Drop Suricata stats events (too verbose, not security relevant)
        if [suricataDataJson][event_type] == "stats" {
            drop {
                id => "suricata-stats-drop"
            }
        }

        # Process Suricata JSON data
        # When FLATTEN_SURICATA=true: Flattens all nested objects for Splunk
        # When FLATTEN_SURICATA!=true: Keeps nested structure for Azure/other outputs
        if "suricata" in [tags] and [suricataDataJson] {
            ruby {
                id => "suricata-process"
                code => '
                    require "json"
                    require "time"

                    data = event.get("suricataDataJson")
                    next unless data.is_a?(Hash)

                    # Fields to drop (high-volume/low-value) - applies to all outputs
                    drop_fields = ["files", "payload", "payload_printable", "packet", "tx_guessed", "policy_id"]
                    tls_skip = ["certificate", "chain"]

                    # Calculate unix timestamp from Suricata timestamp
                    unix_time = nil
                    if data["timestamp"]
                        begin
                            unix_time = Time.parse(data["timestamp"]).to_i
                        rescue
                            unix_time = Time.now.to_i
                        end
                    else
                        unix_time = Time.now.to_i
                    end

                    # Check if flattening is enabled (for Splunk)
                    if ENV["FLATTEN_SURICATA"] == "true"
                        # Helper to flatten a nested object with a prefix
                        def flatten_object(data, obj_name, prefix, skip_keys = [])
                            return {} unless data[obj_name].is_a?(Hash)
                            result = {}
                            data[obj_name].each do |k, v|
                                next if skip_keys.include?(k)
                                if v.is_a?(Hash)
                                    # Handle double-nested objects (e.g., ssh.client.software_version)
                                    v.each do |k2, v2|
                                        next if v2.is_a?(Hash) || v2.is_a?(Array)
                                        result["#{prefix}_#{k}_#{k2}"] = v2
                                    end
                                elsif v.is_a?(Array)
                                    # Take first element for arrays (if primitive)
                                    result["#{prefix}_#{k}"] = v[0] if v[0] && !v[0].is_a?(Hash) && !v[0].is_a?(Array)
                                else
                                    result["#{prefix}_#{k}"] = v
                                end
                            end
                            result
                        end

                        flattened = {}

                        # Nested objects to flatten with their prefixes
                        nested_objects = {
                            "flow" => "flow",
                            "http" => "http",
                            "tls" => "tls",
                            "dns" => "dns",
                            "smtp" => "smtp",
                            "ssh" => "ssh",
                            "fileinfo" => "file",
                            "tcp" => "tcp"
                        }

                        # Process each top-level field
                        data.each do |key, value|
                            next if drop_fields.include?(key)

                            if key == "alert" && value.is_a?(Hash)
                                # Flatten alert fields to top level (no prefix)
                                value.each do |alert_key, alert_value|
                                    next if alert_value.is_a?(Hash) || alert_value.is_a?(Array)
                                    flattened[alert_key] = alert_value
                                end
                            elsif key == "metadata" && value.is_a?(Hash)
                                # Handle metadata specially - arrays take first value, skip timestamps
                                value.each do |meta_key, meta_value|
                                    next if ["created_at", "updated_at"].include?(meta_key)
                                    if meta_value.is_a?(Array)
                                        flattened["meta_#{meta_key}"] = meta_value[0] if meta_value[0]
                                    elsif !meta_value.is_a?(Hash)
                                        flattened["meta_#{meta_key}"] = meta_value
                                    end
                                end
                            elsif nested_objects.key?(key)
                                # Flatten known nested objects with appropriate prefix
                                skip_keys = (key == "tls") ? tls_skip : []
                                flattened.merge!(flatten_object(data, key, nested_objects[key], skip_keys))
                            elsif !value.is_a?(Hash) && !value.is_a?(Array)
                                # Keep primitive top-level fields as-is
                                flattened[key] = value
                            end
                        end

                        # Fix http_ prefix duplication (http.http_method → http_method not http_http_method)
                        flattened.keys.select { |k| k.start_with?("http_http_") }.each do |k|
                            new_key = k.sub("http_http_", "http_")
                            flattened[new_key] = flattened.delete(k)
                        end

                        event_data = flattened
                    else
                        # Non-flattened mode: keep nested structure but remove unwanted fields
                        cleaned = data.dup
                        drop_fields.each { |f| cleaned.delete(f) }
                        if cleaned["tls"].is_a?(Hash)
                            tls_skip.each { |f| cleaned["tls"].delete(f) }
                        end
                        event_data = cleaned
                    end

                    # Build complete HEC payload with event as JSON object
                    payload = {
                        "sourcetype" => "aviatrix:ids",
                        "source" => "avx-ids",
                        "host" => event.get("gw_hostname"),
                        "time" => unix_time,
                        "event" => event_data
                    }
                    event.set("[@metadata][suricata_hec_payload]", payload.to_json)
                '
            }
        }
    }
}

# Gateway Performance Statistics Filter
# Parses AviatrixGwNetStats and AviatrixGwSysStats syslog messages

# Network statistics (interface throughput)
filter {
    if [type] == "syslog" and !("fqdn" in [tags] or "cmd" in [tags] or "microseg" in [tags] or "mitm" in [tags] or "suricata" in [tags]) {
        grok {
            id => "gw_net_stats"
            patterns_dir => ["/usr/share/logstash/patterns"]
            add_tag => ["gw_net_stats"]
            break_on_match => true
            match => {
                "message" => [
                    # With syslog priority prefix and public_ip
                    "<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date}%{DATA}AviatrixGwNetStats:%{DATA}name=%{NOTSPACE:gateway}%{DATA}public_ip=%{IP:public_ip}%{DATA}private_ip=%{IP:private_ip}%{DATA}interface=%{NOTSPACE:interface}%{DATA}total_rx_rate=%{NOTSPACE:total_rx_rate}%{DATA}total_tx_rate=%{NOTSPACE:total_tx_rate}%{DATA}total_rx_tx_rate=%{NOTSPACE:total_rx_tx_rate}%{DATA}total_rx_cum=%{NOTSPACE:total_rx_cum}%{DATA}total_tx_cum=%{NOTSPACE:total_tx_cum}%{DATA}total_rx_tx_cum=%{NOTSPACE:total_rx_tx_cum}",
                    # Without public_ip (firenet interfaces)
                    "<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date}%{DATA}AviatrixGwNetStats:%{DATA}name=%{NOTSPACE:gateway}%{DATA}private_ip=%{IP:private_ip}%{DATA}interface=%{NOTSPACE:interface}%{DATA}total_rx_rate=%{NOTSPACE:total_rx_rate}%{DATA}total_tx_rate=%{NOTSPACE:total_tx_rate}%{DATA}total_rx_tx_rate=%{NOTSPACE:total_rx_tx_rate}%{DATA}total_rx_cum=%{NOTSPACE:total_rx_cum}%{DATA}total_tx_cum=%{NOTSPACE:total_tx_cum}%{DATA}total_rx_tx_cum=%{NOTSPACE:total_rx_tx_cum}"
                ]
            }
        }
    }
}

# System statistics (CPU, memory, disk)
filter {
    if [type] == "syslog" and !("fqdn" in [tags] or "cmd" in [tags] or "microseg" in [tags] or "mitm" in [tags] or "suricata" in [tags] or "gw_net_stats" in [tags]) {
        grok {
            id => "gw_sys_stats"
            patterns_dir => ["/usr/share/logstash/patterns"]
            add_tag => ["gw_sys_stats"]
            break_on_match => true
            match => {
                "message" => [
                    "<%{NUMBER:syslog_pri}>%{SYSLOG_TIMESTAMP:date}%{DATA}AviatrixGwSysStats:%{DATA}name=%{NOTSPACE:gateway}%{DATA}cpu_idle=%{NUMBER:cpu_idle}%{DATA}memory_free=%{NUMBER:memory_free}%{DATA}memory_available=%{NUMBER:memory_available}%{DATA}memory_total=%{NUMBER:memory_total}%{DATA}disk_total=%{NUMBER:disk_total}%{DATA}disk_free=%{NUMBER:disk_free}"
                ]
            }
        }
    }
}

# Tunnel Status Change Filter
# Parses AviatrixTunnelStatusChange syslog messages

filter {
    if [type] == "syslog" {
        grok {
            id => "tunnel_status"
            patterns_dir => ["/usr/share/logstash/patterns"]
            add_tag => ["tunnel_status"]
            break_on_match => true
            match => {
                "message" => [
                    "^%{SYSLOG_TIMESTAMP:date}.*AviatrixTunnelStatusChange.*src_gw=%{TUNNEL_GW:src_gw}.*dst_gw=%{TUNNEL_GW:dst_gw}.*old_state=%{WORD:old_state}.*new_state=%{WORD:new_state}.*"
                ]
            }
        }
    }
}

# Microseg Throttling Filter
# Limits log volume for L4 microseg events to max 2 logs/minute per connection
# This reduces storage costs while maintaining visibility

filter {
    if "microseg" in [tags] and "mitm" not in [tags] {
        # Throttle key includes policy UUID, IPs, ports, and protocol
        # This ensures unique connections are tracked independently
        # Note: Uses dst_ip (correct field name from grok pattern)
        throttle {
            id => "microseg-throttle"
            key => "%{uuid}%{src_ip}%{dst_ip}%{src_port}%{dst_port}%{proto}"
            max_age => 120
            period => "60"
            after_count => 1
            add_tag => "throttled"
        }
    }
}

# Drop throttled events
filter {
    if "throttled" in [tags] {
        drop {
            id => "microseg-throttled"
        }
    }
}

# Timestamp Normalization Filter
# Converts the parsed date field to @timestamp and adds unix_time

filter {
    date {
        id => "date-to-timestamp"
        # Supports multiple timestamp formats:
        # - ISO8601: 2022-05-14T03:46:10.257442+00:00
        # - Long format: 2022-05-14 03:46:10.257442
        # - Short format: May 14 03:46:16
        match => [ "date", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSSSSS", "MMM dd HH:mm:ss" ]
        target => "@timestamp"
        remove_field => [ "date" ]
    }

    # Add unix timestamp for outputs that require epoch time
    ruby {
        id => "add-unix-time"
        code => "event.set('unix_time', event.get('@timestamp').to_i)"
    }
}

# Field Type Conversion Filter
# Converts string fields to their proper types for downstream processing

# Microseg field conversions
filter {
    if "microseg" in [tags] {
        mutate {
            id => "microseg-field-conversion"
            convert => {
                "src_port" => "integer"
                "dst_port" => "integer"
                "enforced" => "boolean"
            }
        }
    }
}

# Gateway network stats field conversions
filter {
    if "gw_net_stats" in [tags] {
        mutate {
            id => "gw_net_stats-rate-conversion"
            convert => {
                "total_rx_rate" => "integer"
                "total_tx_rate" => "integer"
                "total_rx_tx_rate" => "integer"
            }
            gsub => [
                "total_rx_rate", "Kb", "000",
                "total_tx_rate", "Kb", "000",
                "total_rx_tx_rate", "Kb", "000"
            ]
        }
    }
}

# Gateway system stats field conversions
filter {
    if "gw_sys_stats" in [tags] {
        mutate {
            id => "gw_sys_stats-field-conversion"
            convert => {
                "cpu_idle" => "float"
                "memory_free" => "integer"
                "memory_available" => "integer"
                "memory_total" => "integer"
                "disk_total" => "integer"
                "disk_free" => "integer"
            }
        }
    }
}

# ============================================================================
# OUTPUT CONFIGURATION (splunk-hec)
# ============================================================================

# Splunk HTTP Event Collector Output
# Routes events to Splunk based on tags with appropriate source types
#
# Environment Variables:
#   SPLUNK_ADDRESS  - Splunk HEC hostname/IP (required)
#   SPLUNK_PORT     - HEC port (default: 8088)
#   SPLUNK_HEC_AUTH - HEC authentication token (required)

output {
    # Suricata IDS events - flattened structure with alert.* fields at top level
    # Uses pre-built HEC payload to ensure event is a proper JSON object
    if "suricata" in [tags] {
        http {
            id => "splunk-suricata"
            http_method => "post"
            url => "${SPLUNK_ADDRESS}:${SPLUNK_PORT:8088}/services/collector/event"
            headers => ["Authorization", "Splunk ${SPLUNK_HEC_AUTH}"]
            ssl_verification_mode => "none"
            format => "message"
            content_type => "application/json"
            message => "%{[@metadata][suricata_hec_payload]}"
        }
    }

    # L7 DCF / MITM events
    else if "mitm" in [tags] {
        http {
            id => "splunk-mitm"
            http_method => "post"
            url => "${SPLUNK_ADDRESS}:${SPLUNK_PORT:8088}/services/collector/event"
            headers => ["Authorization", "Splunk ${SPLUNK_HEC_AUTH}"]
            ssl_verification_mode => "none"
            format => "json"
            mapping => {
                "sourcetype" => "aviatrix:firewall:l7"
                "source" => "avx-l7-fw"
                "host" => "%{gw_hostname}"
                "time" => "%{unix_time}"
                "event" => "%{[@metadata][payload]}"
            }
        }
    }

    # L4 Microseg events
    else if "microseg" in [tags] {
        http {
            id => "splunk-microseg"
            http_method => "post"
            url => "${SPLUNK_ADDRESS}:${SPLUNK_PORT:8088}/services/collector/event"
            headers => ["Authorization", "Splunk ${SPLUNK_HEC_AUTH}"]
            ssl_verification_mode => "none"
            format => "json"
            mapping => {
                "sourcetype" => "aviatrix:firewall:l4"
                "source" => "avx-l4-fw"
                "host" => "%{gw_hostname}"
                "time" => "%{unix_time}"
                "event" => {
                    "proto" => "%{proto}"
                    "action" => "%{action}"
                    "src_ip" => "%{src_ip}"
                    "src_port" => "%{src_port}"
                    "dst_ip" => "%{dst_ip}"
                    "dst_port" => "%{dst_port}"
                    "enforced" => "%{enforced}"
                    "uuid" => "%{uuid}"
                    "gw_ip" => "%{gw_ip}"
                    "src_mac" => "%{src_mac}"
                    "dst_mac" => "%{dst_mac}"
                    "ip_size" => "%{ip_size}"
                    "session_id" => "%{session_id}"
                    "session_event" => "%{session_event}"
                    "session_end_reason" => "%{session_end_reason}"
                    "session_pkt_cnt" => "%{session_pkt_cnt}"
                    "session_byte_cnt" => "%{session_byte_cnt}"
                    "session_dur" => "%{session_dur}"
                    "syslog" => "%{message}"
                    "timestamp" => "%{unix_time}"
                }
            }
        }
    }

    # FQDN Firewall events
    else if "fqdn" in [tags] {
        http {
            id => "splunk-fqdn"
            http_method => "post"
            url => "${SPLUNK_ADDRESS}:${SPLUNK_PORT:8088}/services/collector/event"
            headers => ["Authorization", "Splunk ${SPLUNK_HEC_AUTH}"]
            ssl_verification_mode => "none"
            format => "json"
            mapping => {
                "sourcetype" => "aviatrix:firewall:fqdn"
                "source" => "avx-fqdn"
                "host" => "%{gateway}"
                "time" => "%{unix_time}"
                "event" => {
                    "sip" => "%{sip}"
                    "dip" => "%{dip}"
                    "gateway" => "%{gateway}"
                    "state" => "%{state}"
                    "hostname" => "%{hostname}"
                    "rule" => "%{rule}"
                    "syslog" => "%{message}"
                    "timestamp" => "%{unix_time}"
                }
            }
        }
    }

    # Controller CMD/API events
    else if "cmd" in [tags] {
        http {
            id => "splunk-cmd"
            http_method => "post"
            url => "${SPLUNK_ADDRESS}:${SPLUNK_PORT:8088}/services/collector/event"
            headers => ["Authorization", "Splunk ${SPLUNK_HEC_AUTH}"]
            ssl_verification_mode => "none"
            format => "json"
            mapping => {
                "sourcetype" => "aviatrix:controller:audit"
                "source" => "avx-cmd"
                "host" => "%{gw_hostname}"
                "time" => "%{unix_time}"
                "event" => {
                    "action" => "%{action}"
                    "args" => "%{args}"
                    "result" => "%{result}"
                    "reason" => "%{reason}"
                    "username" => "%{username}"
                    "syslog" => "%{message}"
                    "timestamp" => "%{unix_time}"
                }
            }
        }
    }

    # Gateway network statistics
    else if "gw_net_stats" in [tags] {
        http {
            id => "splunk-gw-net-stats"
            http_method => "post"
            url => "${SPLUNK_ADDRESS}:${SPLUNK_PORT:8088}/services/collector/event"
            headers => ["Authorization", "Splunk ${SPLUNK_HEC_AUTH}"]
            ssl_verification_mode => "none"
            format => "json"
            mapping => {
                "sourcetype" => "aviatrix:gateway:network"
                "source" => "avx-gw-net-stats"
                "host" => "%{gateway}"
                "time" => "%{unix_time}"
                "event" => {
                    "gateway" => "%{gateway}"
                    "public_ip" => "%{public_ip}"
                    "private_ip" => "%{private_ip}"
                    "interface" => "%{interface}"
                    "total_rx_rate" => "%{total_rx_rate}"
                    "total_tx_rate" => "%{total_tx_rate}"
                    "total_rx_tx_rate" => "%{total_rx_tx_rate}"
                    "total_rx_cum" => "%{total_rx_cum}"
                    "total_tx_cum" => "%{total_tx_cum}"
                    "total_rx_tx_cum" => "%{total_rx_tx_cum}"
                    "syslog" => "%{message}"
                }
            }
        }
    }

    # Gateway system statistics
    else if "gw_sys_stats" in [tags] {
        http {
            id => "splunk-gw-sys-stats"
            http_method => "post"
            url => "${SPLUNK_ADDRESS}:${SPLUNK_PORT:8088}/services/collector/event"
            headers => ["Authorization", "Splunk ${SPLUNK_HEC_AUTH}"]
            ssl_verification_mode => "none"
            format => "json"
            mapping => {
                "sourcetype" => "aviatrix:gateway:system"
                "source" => "avx-gw-sys-stats"
                "host" => "%{gateway}"
                "time" => "%{unix_time}"
                "event" => {
                    "gateway" => "%{gateway}"
                    "cpu_idle" => "%{cpu_idle}"
                    "memory_free" => "%{memory_free}"
                    "memory_available" => "%{memory_available}"
                    "memory_total" => "%{memory_total}"
                    "disk_total" => "%{disk_total}"
                    "disk_free" => "%{disk_free}"
                    "syslog" => "%{message}"
                }
            }
        }
    }

    # Tunnel status changes
    else if "tunnel_status" in [tags] {
        http {
            id => "splunk-tunnel-status"
            http_method => "post"
            url => "${SPLUNK_ADDRESS}:${SPLUNK_PORT:8088}/services/collector/event"
            headers => ["Authorization", "Splunk ${SPLUNK_HEC_AUTH}"]
            ssl_verification_mode => "none"
            format => "json"
            mapping => {
                "sourcetype" => "aviatrix:tunnel:status"
                "source" => "avx-tunnel-status"
                "host" => "%{gateway}"
                "time" => "%{unix_time}"
                "event" => {
                    "src_gw" => "%{src_gw}"
                    "dst_gw" => "%{dst_gw}"
                    "old_state" => "%{old_state}"
                    "new_state" => "%{new_state}"
                    "syslog" => "%{message}"
                }
            }
        }
    }
}
